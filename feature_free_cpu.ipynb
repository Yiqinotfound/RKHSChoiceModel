{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json \n",
    "import pandas as pd \n",
    "from scipy.special import gamma, kv\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "instance_id = 4\n",
    "\n",
    "# kernel_type = 'matern'\n",
    "# kernel_params = {'length_scale': 1.0, 'nu':1.5, 'sigma': 1.0}\n",
    "\n",
    "kernel_type = 'gaussian'\n",
    "kernel_params = {'length_scale': 1.0, 'sigma': 1.0}\n",
    "\n",
    "loss_type = 'mse'\n",
    "# loss_type = 'cross_entrophy'\n",
    "\n",
    "# kernel_type = 'sigmoid'\n",
    "# kernel_params = {'alpha': 0.5, 'c': 1.0, 'sigma':1.0}\n",
    "\n",
    "\n",
    "# kernel_type = 'laplace'\n",
    "# kernel_params = {'sigma': 1.0}\n",
    "\n",
    "\n",
    "kernel_params_str = \"_\".join([f\"{key}={value}\" for key, value in kernel_params.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Data, Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_df(json_file_path:str):\n",
    "    with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    in_sample_transactions = data[\"transactions\"][\"in_sample_transactions\"]\n",
    "    out_sample_transactions = data[\"transactions\"][\"out_of_sample_transactions\"]\n",
    "    product_labels = data['product_labels']\n",
    "\n",
    "    in_sample_transactions = pd.DataFrame(in_sample_transactions)\n",
    "    out_sample_transactions = pd.DataFrame(out_sample_transactions)\n",
    "    \n",
    "    # rename 'prodcut' to 'choice' \n",
    "    in_sample_transactions.rename(columns={'product':'choice'}, inplace=True)\n",
    "    out_sample_transactions.rename(columns={'product':'choice'}, inplace=True)\n",
    "    product_labels = pd.DataFrame(\n",
    "        list(product_labels.items()), columns=[\"product_id\", \"product_name\"]\n",
    "    )\n",
    "    return in_sample_transactions, out_sample_transactions,product_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_one_hot(transaction:list,d):\n",
    "    one_hot = np.zeros(d)\n",
    "    for item in transaction:\n",
    "        one_hot[item] = 1\n",
    "    return one_hot\n",
    "\n",
    "def convert_to_one_hot(transactions:pd.DataFrame,d):\n",
    "    transactions[\"offered_product_one_hot\"] = transactions['offered_products'].apply(lambda x : convert_list_to_one_hot(x,d))\n",
    "    transactions['choice_one_hot'] = transactions['choice'].apply(lambda x: convert_list_to_one_hot([x],d))\n",
    "    return transactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offered_products</th>\n",
       "      <th>choice</th>\n",
       "      <th>offered_product_one_hot</th>\n",
       "      <th>choice_one_hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     offered_products  choice    offered_product_one_hot  \\\n",
       "0     [0, 1, 2, 3, 4]       3  [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "1     [0, 1, 2, 3, 4]       0  [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "2     [0, 1, 2, 3, 4]       0  [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "3     [0, 1, 2, 3, 4]       0  [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "4     [0, 1, 2, 3, 4]       0  [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "...               ...     ...                        ...   \n",
       "1095  [0, 1, 2, 3, 4]       1  [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "1096  [0, 1, 2, 3, 4]       0  [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "1097  [0, 1, 2, 3, 4]       0  [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "1098  [0, 1, 2, 3, 4]       0  [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "1099  [0, 1, 2, 3, 4]       0  [1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "\n",
       "                 choice_one_hot  \n",
       "0     [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "1     [1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2     [1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3     [1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4     [1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "...                         ...  \n",
       "1095  [0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "1096  [1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1097  [1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1098  [1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1099  [1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "\n",
       "[1100 rows x 4 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample_transactions, out_sample_transactions ,items= convert_json_to_df(f\"hotel_json/instance_{instance_id}.json\")\n",
    "d = len(items) + 1 # consider the 0 as no-purchase\n",
    "datasize = len(in_sample_transactions)\n",
    "in_sample_transactions = convert_to_one_hot(in_sample_transactions,d)\n",
    "out_sample_transactions = convert_to_one_hot(out_sample_transactions,d)\n",
    "\n",
    "in_sample_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Kernel Implementation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-valued **Matern kernel** $\\tilde{\\boldsymbol{\\mathsf{k}}}$ can be \n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\mathsf{k}}(\\boldsymbol{e}_{S},\\boldsymbol{e}_{S'}) = \\boldsymbol{K} \\otimes \\mathsf{k}_{m}(\\boldsymbol{e}_{S}, \\boldsymbol{e}_{S'})\n",
    "$$\n",
    "where $\\boldsymbol{K}$ is a positive semi-definite matrix. Then \n",
    "\n",
    "$$\n",
    "\\tilde{\\mathsf{k}}^{ij}(\\boldsymbol{e}_{S},\\boldsymbol{e}_{S'}) = K_{ij} \\times\\sigma^{2} \\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\left( \\sqrt{ 2\\nu }  \\frac{\\left\\| \\boldsymbol{e}_{S} - \\boldsymbol{e}_{S'} \\right\\|_{2}  }{\\ell} \\right) K_{\\nu} \\left( \\sqrt{ 2\\nu } \\frac{\\left\\| \\boldsymbol{\\boldsymbol{e}_{S}-\\boldsymbol{e}_{S'}} \\right\\|_{2}  }{\\ell} \\right)\n",
    "$$\n",
    "Add constraint, \n",
    "\n",
    "$$\n",
    "\\mathsf{k}^{ij}(S, S') = \\mathbb{1}(i \\in \\boldsymbol{e}_{S})\\cdot \\mathbb{1}(j \\in \\boldsymbol{e}_{S'}) \\cdot   \\tilde{\\mathsf{k}}^{ij}(\\boldsymbol{e}_{S}, \\boldsymbol{e}_{S'})\n",
    "$$\n",
    "\n",
    "\n",
    "Same with Gaussian kernel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.eye(d) # for the moment we consider the identity matrix as the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scalar_matern_kernel(length_scale:float, nu:float, sigma:float):\n",
    "    \"\"\"\n",
    "    Input: kernel parameters and index (i,j)\n",
    "    generate base scalar-valued Matern kernel at (i,j) \n",
    "    return {k_m}_ij\n",
    "    \"\"\"\n",
    "    def kernel(x1:torch.Tensor, x2:torch.Tensor):\n",
    "        dist = torch.norm(x1 - x2)\n",
    "        \n",
    "        if dist == 0:\n",
    "            return sigma**2\n",
    "\n",
    "        # calculate the factor\n",
    "        factor = (2 ** (1 - nu)) / gamma(nu)\n",
    "        scaled_dist = np.sqrt(2 * nu) * dist / length_scale\n",
    "        result = sigma**2 * factor * (scaled_dist**nu) * kv(nu, scaled_dist)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "def generate_scalar_gaussian_kernel(length_scale:float, sigma:float):\n",
    "    \"\"\"\n",
    "    Input: kernel parameters and index (i,j)\n",
    "    generate base scalar-valued Gaussian kernel at (i,j)\n",
    "    return {k_g}_ij\n",
    "    \"\"\"\n",
    "    def kernel(x1:torch.Tensor, x2:torch.Tensor):\n",
    "        \n",
    "        dist = torch.norm (x1-x2)\n",
    "        return sigma**2 * torch.exp(-dist**2 / (2 * length_scale**2))\n",
    "    return kernel\n",
    "\n",
    "def generate_scalar_sigmoid_kernel(alpha: float, c: float, sigma: float):\n",
    "    \"\"\"\n",
    "    Input: kernel parameters alpha, c, and sigma\n",
    "    Generate base scalar-valued Sigmoid kernel at (i,j)\n",
    "    return {k_s}_ij\n",
    "    \"\"\"\n",
    "    def kernel(x1: torch.Tensor, x2: torch.Tensor):\n",
    "\n",
    "        dot_product = torch.matmul(x1, x2)\n",
    "        return sigma**2 * torch.tanh(alpha * dot_product + c)\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "\n",
    "\n",
    "def generate_laplace_kernel(sigma: float):\n",
    "    \"\"\"\n",
    "    Generates the Laplace kernel (based on L1 distance).\n",
    "    \n",
    "    Input:\n",
    "        sigma: The scale parameter for the kernel.\n",
    "    \n",
    "    Returns:\n",
    "        kernel: The Laplace kernel function.\n",
    "    \"\"\"\n",
    "    def kernel(x1: torch.Tensor, x2: torch.Tensor):\n",
    "        distance = torch.sum(torch.abs(x1 - x2))  \n",
    "        return torch.exp(-distance / sigma)\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "def generate_scalar_anova_kernel(sigma: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Generates the ANOVA kernel (a product of independent Gaussian kernels)\n",
    "\n",
    "    Input:\n",
    "        sigma: A 1D tensor of length scale parameters for each dimension.\n",
    "\n",
    "    Returns:\n",
    "        kernel: The ANOVA kernel function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def kernel(x1: torch.Tensor, x2: torch.Tensor):\n",
    "\n",
    "        diff = x1 - x2\n",
    "        kernel_values = torch.exp(-0.5 * (diff ** 2) / (sigma ** 2))\n",
    "        return torch.prod(kernel_values)\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "\n",
    "def generate_matrix_kernel(scalar_kernel):\n",
    "    def kernel(x1:torch.Tensor, x2:torch.Tensor):\n",
    "        scalar_kernel_value = scalar_kernel(x1, x2)\n",
    "        \n",
    "        mask_x1 = x1 != 0\n",
    "        mask_x2 = x2 != 0\n",
    "\n",
    "        mask_x1_expand = mask_x1.view(-1, 1).expand(d, d)\n",
    "        mask_x2_expand = mask_x2.view(1, -1).expand(d, d)\n",
    "        \n",
    "        result = scalar_kernel_value * K * mask_x1_expand * mask_x2_expand\n",
    "        return result\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_kernel = None\n",
    "if kernel_type == 'matern':\n",
    "    scalar_kernel = generate_scalar_matern_kernel(kernel_params['length_scale'], kernel_params['nu'], kernel_params['sigma'])\n",
    "elif kernel_type == 'gaussian':\n",
    "    scalar_kernel = generate_scalar_gaussian_kernel(kernel_params['length_scale'], kernel_params['sigma'])\n",
    "elif kernel_type == 'sigmoid':\n",
    "    scalar_kernel = generate_scalar_sigmoid_kernel(kernel_params['alpha'], kernel_params['c'], kernel_params['sigma'])\n",
    "elif kernel_type == 'anova':\n",
    "    scalar_kernel = generate_scalar_anova_kernel(kernel_params['sigma'])\n",
    "elif kernel_type == 'laplace':\n",
    "    scalar_kernel = generate_laplace_kernel(kernel_params['sigma'])\n",
    "    \n",
    "matrix_kernel = generate_matrix_kernel(scalar_kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Precalcualte Kernel Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1210000/1210000 [02:13<00:00, 9068.24iteration/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "total_iterations = datasize * datasize\n",
    "with tqdm(total=total_iterations, desc=\"Overall Progress\", unit=\"iteration\") as pbar:\n",
    "    K_kernel = torch.zeros(datasize,datasize,d,d,dtype=torch.float32)\n",
    "\n",
    "    for i in range(datasize):\n",
    "        for j in range(datasize):\n",
    "            S_i = torch.tensor(in_sample_transactions[\"offered_product_one_hot\"][i],dtype=torch.float32)\n",
    "            S_j = torch.tensor(in_sample_transactions[\"offered_product_one_hot\"][j],dtype=torch.float32)\n",
    "            K_kernel[i, j] = matrix_kernel(\n",
    "                S_i,\n",
    "                S_j,\n",
    "            )\n",
    "\n",
    "            pbar.update(1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "kernel_data_save_path = f\"results/feature_free/hotel_{instance_id}/kernel_data/{kernel_type}({kernel_params_str})_kernel_data.pt\"\n",
    "os.makedirs(os.path.dirname(kernel_data_save_path), exist_ok=True)\n",
    "torch.save(\n",
    "    K_kernel,\n",
    "    f\"results/feature_free/hotel_{instance_id}/kernel_data/{kernel_type}({kernel_params_str})_kernel_data.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Solve Using `torch.optimin.Adam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_kernel = torch.load(\n",
    "    f\"results/feature_free/hotel_{instance_id}/kernel_data/{kernel_type}({kernel_params_str})_kernel_data.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Best Loss: 2.1053805351257324\n",
      "Epoch 10, Best Loss: 0.46666282415390015\n",
      "Epoch 20, Best Loss: 0.46666282415390015\n",
      "Epoch 30, Best Loss: 0.38745447993278503\n",
      "Epoch 40, Best Loss: 0.38745447993278503\n",
      "Epoch 50, Best Loss: 0.38745447993278503\n",
      "Epoch 60, Best Loss: 0.36232060194015503\n",
      "Epoch 70, Best Loss: 0.36232060194015503\n",
      "Epoch 80, Best Loss: 0.36232060194015503\n",
      "Epoch 90, Best Loss: 0.36232060194015503\n",
      "Early stopping at epoch 94, Best Loss: 0.36232060194015503\n"
     ]
    }
   ],
   "source": [
    "alphaset = torch.randn((datasize, d), dtype=torch.float32, requires_grad=True)\n",
    "lambda_ = 1e-4\n",
    "grad_clip_threshold = 2.0\n",
    "patience = 40\n",
    "best_loss = float('inf')  \n",
    "epochs_since_improvement = 0\n",
    "best_alphaset = None\n",
    "\n",
    "def objective(alphaset: torch.Tensor):\n",
    "    U = torch.zeros((datasize, d), dtype=torch.float32)\n",
    "    U = torch.einsum(\"ijab, jb -> ia\", K_kernel, alphaset)\n",
    "\n",
    "    l = loss(U)\n",
    "    r = reg(alphaset)\n",
    "\n",
    "    return l + lambda_ * r\n",
    "\n",
    "\n",
    "\n",
    "def loss(U: torch.Tensor):\n",
    "\n",
    "    loss_value = 0.0\n",
    "    for i in range(datasize):\n",
    "\n",
    "        p_vec = torch.zeros((d, 1), dtype=torch.float32)\n",
    "\n",
    "        hS_i = torch.tensor(\n",
    "            in_sample_transactions.iloc[i][\"offered_product_one_hot\"],\n",
    "            dtype=torch.float32,\n",
    "        ).view(-1, 1)\n",
    "\n",
    "        y_i = torch.tensor(\n",
    "            in_sample_transactions.iloc[i][\"choice_one_hot\"], dtype=torch.float32\n",
    "        ).view(-1, 1)\n",
    "\n",
    "        utility_hSi = U[i].view(-1, 1)\n",
    "        exp_utility = torch.exp(utility_hSi)\n",
    "        sum_exp_utility = torch.sum(exp_utility) \n",
    "\n",
    "        for j in range(d):\n",
    "\n",
    "            if hS_i[j] == 1:\n",
    "\n",
    "                p_vec[j] = torch.exp(utility_hSi[j]) / sum_exp_utility\n",
    "            else:\n",
    "\n",
    "                p_vec[j] = 0\n",
    "\n",
    "        loss_value += loss_func(p_vec, y_i)\n",
    "    return loss_value / datasize\n",
    "\n",
    "\n",
    "def cross_entropy_loss(p_vec: torch.Tensor, y_vec: torch.Tensor):\n",
    "    for i in range(d):\n",
    "        if y_vec[i] == 1:\n",
    "            return -torch.log(p_vec[i])\n",
    "\n",
    "\n",
    "def squared_loss(p_vec: torch.Tensor, y_vec: torch.Tensor):\n",
    "    return torch.sum((p_vec - y_vec) ** 2)\n",
    "\n",
    "\n",
    "def reg(alphaset: torch.Tensor):\n",
    "\n",
    "    alphaset = alphaset.unsqueeze(2)  # add a dimension \n",
    "\n",
    "    # einsum\n",
    "    result = torch.einsum(\"ikd,ijkl,jle->\", alphaset, K_kernel, alphaset)\n",
    "\n",
    "    return result\n",
    "\n",
    "def compute_gradient():\n",
    "    objective_value = objective(alphaset)\n",
    "    objective_value.backward() \n",
    "    return alphaset.grad\n",
    "\n",
    "loss_func = None\n",
    "if loss_type == 'cross_entrophy':\n",
    "    loss_func = cross_entropy_loss\n",
    "elif loss_type == 'mse':\n",
    "    loss_func = squared_loss\n",
    "\n",
    "optimizer = torch.optim.Adam([alphaset], lr=0.01)\n",
    "\n",
    "for epoch in range(400):\n",
    "    optimizer.zero_grad()  \n",
    "    loss_value = objective(alphaset)\n",
    "\n",
    "    \n",
    "    if loss_value.item() < best_loss:\n",
    "        best_loss = loss_value.item()\n",
    "        epochs_since_improvement = 0  \n",
    "        best_alphaset = alphaset.clone().detach()\n",
    "    else:\n",
    "        epochs_since_improvement += 1\n",
    "        \n",
    "    if epochs_since_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}, Best Loss: {best_loss}\")\n",
    "        break  \n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Best Loss: {best_loss}\")\n",
    "    \n",
    "    loss_value.backward()  \n",
    "    torch.nn.utils.clip_grad_norm_([alphaset], grad_clip_threshold)\n",
    "    optimizer.step()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_utility(S:torch.Tensor):\n",
    "    utility_vec = torch.zeros((d,1),dtype=torch.float32)\n",
    "    for i in range(datasize):\n",
    "        S_i = torch.tensor(in_sample_transactions[\"offered_product_one_hot\"][i],dtype=torch.float32)\n",
    "        kernel_value = matrix_kernel(S, S_i)\n",
    "        utility_vec += kernel_value @ best_alphaset[i].view(-1,1)\n",
    "    return utility_vec\n",
    "\n",
    "def cal_probability(S:np.ndarray):\n",
    "    utility_vec = cal_utility(S)\n",
    "    sum_exp_utility = torch.sum(torch.exp(utility_vec))\n",
    "    p_vec = torch.zeros(d,dtype=torch.float32)\n",
    "    for i in range(d):\n",
    "        if S[i] == 1:\n",
    "           p_vec[i] = torch.exp(utility_vec[i]) / sum_exp_utility \n",
    "        else:\n",
    "            p_vec[i] = 0\n",
    "            \n",
    "    return p_vec\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2935e-02, 5.7832e-06, 9.8536e-01, 0.0000e+00, 0.0000e+00],\n",
       "        [1.2935e-02, 5.7832e-06, 9.8536e-01, 0.0000e+00, 0.0000e+00],\n",
       "        [1.2935e-02, 5.7832e-06, 9.8536e-01, 0.0000e+00, 0.0000e+00],\n",
       "        ...,\n",
       "        [6.2992e-06, 4.1263e-09, 1.3609e-04, 9.9969e-01, 0.0000e+00],\n",
       "        [6.2992e-06, 4.1263e-09, 1.3609e-04, 9.9969e-01, 0.0000e+00],\n",
       "        [6.2992e-06, 4.1263e-09, 1.3609e-04, 9.9969e-01, 0.0000e+00]])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "S_test = torch.stack([torch.tensor(sample, dtype=torch.float32) for sample in out_sample_transactions[\"offered_product_one_hot\"]])\n",
    "test_p_vecs = torch.stack([cal_probability(S) for S in S_test])\n",
    "test_choice_vecs = torch.stack([torch.tensor(sample, dtype=torch.float32) for sample in out_sample_transactions[\"choice_one_hot\"]])\n",
    "test_p_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5626776732540368, 0.31660616397857666)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse = torch.mean((test_p_vecs- test_choice_vecs) ** 2).item()\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_rmse,test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3273162245750427, 0.5721155692471956)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_train = torch.stack([torch.tensor(sample, dtype=torch.float32) for sample in in_sample_transactions[\"offered_product_one_hot\"]])\n",
    "train_p_vecs = torch.stack([cal_probability(S) for S in S_train])\n",
    "train_choice_vecs = torch.stack([torch.tensor(sample, dtype=torch.float32) for sample in in_sample_transactions[\"choice_one_hot\"]])\n",
    "train_mse = torch.mean((train_p_vecs - train_choice_vecs) ** 2).item()\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_mse, train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "results = [\n",
    "    [instance_id, test_rmse, train_rmse, lambda_,kernel_type , kernel_params_str,loss_type]\n",
    "]\n",
    "file_path = f'results/results.csv'\n",
    "file_exists = os.path.exists(file_path)\n",
    "with open(file_path, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    if not file_exists or os.stat(file_path).st_size == 0:\n",
    "        writer.writerow([\"instance_id\", \"test_rmse\", \"train_rmse\", \"lambda_\", \"kernel_type\", \"kernel_params\",\"loss_type\"])\n",
    "    writer.writerows(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
