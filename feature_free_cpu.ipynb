{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json \n",
    "import pandas as pd \n",
    "from scipy.special import gamma, kv\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Data, Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_df(json_file_path:str):\n",
    "    with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    in_sample_transactions = data[\"transactions\"][\"in_sample_transactions\"]\n",
    "    out_sample_transactions = data[\"transactions\"][\"out_of_sample_transactions\"]\n",
    "    product_labels = data['product_labels']\n",
    "\n",
    "    in_sample_transactions = pd.DataFrame(in_sample_transactions)\n",
    "    out_sample_transactions = pd.DataFrame(out_sample_transactions)\n",
    "    \n",
    "    # rename 'prodcut' to 'choice' \n",
    "    in_sample_transactions.rename(columns={'product':'choice'}, inplace=True)\n",
    "    out_sample_transactions.rename(columns={'product':'choice'}, inplace=True)\n",
    "    product_labels = pd.DataFrame(\n",
    "        list(product_labels.items()), columns=[\"product_id\", \"product_name\"]\n",
    "    )\n",
    "    return in_sample_transactions, out_sample_transactions,product_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_one_hot(transaction:list,d):\n",
    "    one_hot = np.zeros(d)\n",
    "    for item in transaction:\n",
    "        one_hot[item] = 1\n",
    "    return one_hot\n",
    "\n",
    "def convert_to_one_hot(transactions:pd.DataFrame,d):\n",
    "    transactions[\"offered_product_one_hot\"] = transactions['offered_products'].apply(lambda x : convert_list_to_one_hot(x,d))\n",
    "    transactions['choice_one_hot'] = transactions['choice'].apply(lambda x: convert_list_to_one_hot([x],d))\n",
    "    return transactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offered_products</th>\n",
       "      <th>choice</th>\n",
       "      <th>offered_product_one_hot</th>\n",
       "      <th>choice_one_hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>6</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 1, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>[0, 1, 3, 4, 6, 7, 8, 9, 10]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>[0, 1, 3, 4, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>[0, 1, 3, 4, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>[0, 1, 3, 4, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>[0, 1, 3, 4, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5290 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     offered_products  choice  \\\n",
       "0     [0, 1, 3, 4, 5, 6, 7, 8, 9, 10]       6   \n",
       "1     [0, 1, 3, 4, 5, 6, 7, 8, 9, 10]       0   \n",
       "2     [0, 1, 3, 4, 5, 6, 7, 8, 9, 10]       0   \n",
       "3     [0, 1, 3, 4, 5, 6, 7, 8, 9, 10]       0   \n",
       "4     [0, 1, 3, 4, 5, 6, 7, 8, 9, 10]       0   \n",
       "...                               ...     ...   \n",
       "5285     [0, 1, 3, 4, 6, 7, 8, 9, 10]       1   \n",
       "5286     [0, 1, 3, 4, 6, 7, 8, 9, 10]       0   \n",
       "5287     [0, 1, 3, 4, 6, 7, 8, 9, 10]       0   \n",
       "5288     [0, 1, 3, 4, 6, 7, 8, 9, 10]       0   \n",
       "5289     [0, 1, 3, 4, 6, 7, 8, 9, 10]       0   \n",
       "\n",
       "                                offered_product_one_hot  \\\n",
       "0     [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1     [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2     [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3     [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4     [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "...                                                 ...   \n",
       "5285  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...   \n",
       "5286  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...   \n",
       "5287  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...   \n",
       "5288  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...   \n",
       "5289  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                         choice_one_hot  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "1     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "5285  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5286  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5287  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5288  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5289  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[5290 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_id = 1\n",
    "in_sample_transactions, out_sample_transactions ,items= convert_json_to_df(f\"hotel_json/instance_{instance_id}.json\")\n",
    "d = len(items) + 1 # consider the 0 as no-purchase\n",
    "datasize = len(in_sample_transactions)\n",
    "in_sample_transactions = convert_to_one_hot(in_sample_transactions,d)\n",
    "out_sample_transactions = convert_to_one_hot(out_sample_transactions,d)\n",
    "\n",
    "in_sample_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Kernel Implementation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-valued **Matern kernel** $\\tilde{\\boldsymbol{\\mathsf{k}}}$ can be \n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\mathsf{k}}(\\boldsymbol{e}_{S},\\boldsymbol{e}_{S'}) = \\boldsymbol{K} \\otimes \\mathsf{k}_{m}(\\boldsymbol{e}_{S}, \\boldsymbol{e}_{S'})\n",
    "$$\n",
    "where $\\boldsymbol{K}$ is a positive semi-definite matrix. Then \n",
    "\n",
    "$$\n",
    "\\tilde{\\mathsf{k}}^{ij}(\\boldsymbol{e}_{S},\\boldsymbol{e}_{S'}) = K_{ij} \\times\\sigma^{2} \\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\left( \\sqrt{ 2\\nu }  \\frac{\\left\\| \\boldsymbol{e}_{S} - \\boldsymbol{e}_{S'} \\right\\|_{2}  }{\\ell} \\right) K_{\\nu} \\left( \\sqrt{ 2\\nu } \\frac{\\left\\| \\boldsymbol{\\boldsymbol{e}_{S}-\\boldsymbol{e}_{S'}} \\right\\|_{2}  }{\\ell} \\right)\n",
    "$$\n",
    "Add constraint, \n",
    "\n",
    "$$\n",
    "\\mathsf{k}^{ij}(S, S') = \\mathbb{1}(i \\in \\boldsymbol{e}_{S})\\cdot \\mathbb{1}(j \\in \\boldsymbol{e}_{S'}) \\cdot   \\tilde{\\mathsf{k}}^{ij}(\\boldsymbol{e}_{S}, \\boldsymbol{e}_{S'})\n",
    "$$\n",
    "\n",
    "\n",
    "Same with Gaussian kernel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.eye(d) # for the moment we consider the identity matrix as the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_scale=1 \n",
    "nu= 1\n",
    "sigma = 1\n",
    "\n",
    "\n",
    "def generate_scalar_matern_kernel(length_scale:float, nu:float, sigma:float):\n",
    "    \"\"\"\n",
    "    Input: kernel parameters and index (i,j)\n",
    "    generate base scalar-valued Matern kernel at (i,j) \n",
    "    return {k_m}_ij\n",
    "    \"\"\"\n",
    "    def kernel(x1:torch.Tensor, x2:torch.Tensor):\n",
    "        dist = torch.norm(x1 - x2)\n",
    "        \n",
    "        if dist == 0:\n",
    "            return sigma**2\n",
    "\n",
    "        # calculate the factor\n",
    "        factor = (2 ** (1 - nu)) / gamma(nu)\n",
    "        scaled_dist = np.sqrt(2 * nu) * dist / length_scale\n",
    "        result = sigma**2 * factor * (scaled_dist**nu) * kv(nu, scaled_dist)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "# def generate_scalar_gaussian_kernel(length_scale:float, sigma:float):\n",
    "#     \"\"\"\n",
    "#     Input: kernel parameters and index (i,j)\n",
    "#     generate base scalar-valued Gaussian kernel at (i,j)\n",
    "#     return {k_g}_ij\n",
    "#     \"\"\"\n",
    "#     def kernel(x1:np.ndarray, x2:np.ndarray):\n",
    "        \n",
    "#         dist = np.linalg.norm(x1 - x2)\n",
    "#         return sigma**2 * np.exp(-dist**2 / (2 * length_scale**2))\n",
    "#     return kernel\n",
    "\n",
    "def generate_matrix_matern_kernel(length_scale, nu, sigma):\n",
    "    scalar_kernel = generate_scalar_matern_kernel(length_scale, nu, sigma)\n",
    "    \n",
    "    def kernel(x1:torch.Tensor, x2:torch.Tensor):\n",
    "        scalar_kernel_value = scalar_kernel(x1, x2)\n",
    "        \n",
    "        mask_x1 = x1 != 0\n",
    "        mask_x2 = x2 != 0\n",
    "        \n",
    "        mask_x1_expand = mask_x1.view(-1, 1).expand(d, d) \n",
    "        mask_x2_expand = mask_x2.view(1, -1).expand(d, d)\n",
    "        \n",
    "        result = scalar_kernel_value * K* mask_x1_expand * mask_x2_expand \n",
    "\n",
    "        return result \n",
    "    return kernel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def generate_matrix_gaussian_kernel(length_scale, sigma):\n",
    "#     \"\"\"\n",
    "#     generate a matrix-valued Gaussian kernel \n",
    "#     \"\"\"\n",
    "#     scalar_gaussian_kernel = generate_scalar_gaussian_kernel(length_scale, sigma)\n",
    "#     def kernel(x1:np.ndarray,x2:np.ndarray):\n",
    "#         dim = x1.shape[0]\n",
    "#         result = np.zeros((dim,dim))\n",
    "#         for i in range(dim):\n",
    "#             for j in range(dim):\n",
    "#                 if x1[i] == 0 or x2[j] == 0:\n",
    "#                     result[i,j] = 0\n",
    "#                 else:\n",
    "#                     result[i,j] = scalar_gaussian_kernel(x1, x2) * K[i,j]\n",
    "#         return result\n",
    "#     return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_matern_kernel = generate_matrix_matern_kernel(length_scale, nu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Precalcualte Kernel Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress: 100%|██████████| 27984100/27984100 [48:00<00:00, 9716.37iteration/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "total_iterations = datasize * datasize\n",
    "with tqdm(total=total_iterations, desc=\"Overall Progress\", unit=\"iteration\") as pbar:\n",
    "    K_kernel = torch.zeros(datasize,datasize,d,d,dtype=torch.float16)\n",
    "\n",
    "    for i in range(datasize):\n",
    "        for j in range(datasize):\n",
    "            S_i = torch.tensor(in_sample_transactions[\"offered_product_one_hot\"][i],dtype=torch.float16)\n",
    "            S_j = torch.tensor(in_sample_transactions[\"offered_product_one_hot\"][j],dtype=torch.float16)\n",
    "            K_kernel[i, j] = matrix_matern_kernel(\n",
    "                S_i,\n",
    "                S_j,\n",
    "            )\n",
    "\n",
    "            pbar.update(1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "kernel_data_save_path = f\"results/feature_free/hotel_{instance_id}/kernel_data/Matern({length_scale},{nu},{sigma})_kernel_data.pt\"\n",
    "os.makedirs(os.path.dirname(kernel_data_save_path), exist_ok=True)\n",
    "torch.save(K_kernel, f\"results/feature_free/hotel_{instance_id}/kernel_data/Matern({length_scale},{nu},{sigma})_kernel_data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Solve Using `torch.optimin.Adam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_kernel = torch.load(f\"results/feature_free/hotel_{instance_id}/kernel_data/Matern({length_scale},{nu},{sigma})_kernel_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"baddbmm_with_gemm\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m400\u001b[39m):\n\u001b[0;32m     79\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \n\u001b[1;32m---> 80\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphaset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_value\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m best_loss:\n\u001b[0;32m     84\u001b[0m         best_loss \u001b[38;5;241m=\u001b[39m loss_value\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(alphaset)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(alphaset: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m     10\u001b[0m     U \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((datasize, d), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[1;32m---> 11\u001b[0m     U \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mijab, jb -> ia\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphaset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     l \u001b[38;5;241m=\u001b[39m loss(U)\n\u001b[0;32m     14\u001b[0m     r \u001b[38;5;241m=\u001b[39m reg(alphaset)\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\functional.py:377\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    379\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"baddbmm_with_gemm\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "alphaset = torch.randn((datasize, d), dtype=torch.float32, requires_grad=True)\n",
    "lambda_ = 1e-4\n",
    "grad_clip_threshold = 2.0\n",
    "patience = 30\n",
    "best_loss = float('inf')  \n",
    "epochs_since_improvement = 0\n",
    "best_alphaset = None\n",
    "\n",
    "def objective(alphaset: torch.Tensor):\n",
    "    U = torch.zeros((datasize, d), dtype=torch.float32)\n",
    "    U = torch.einsum(\"ijab, jb -> ia\", K_kernel, alphaset)\n",
    "\n",
    "    l = loss(U)\n",
    "    r = reg(alphaset)\n",
    "\n",
    "    return l + lambda_ * r\n",
    "\n",
    "\n",
    "\n",
    "def loss(U: torch.Tensor):\n",
    "\n",
    "    loss_value = 0.0\n",
    "    for i in range(datasize):\n",
    "\n",
    "        p_vec = torch.zeros((d, 1), dtype=torch.float32)\n",
    "\n",
    "        hS_i = torch.tensor(\n",
    "            in_sample_transactions.iloc[i][\"offered_product_one_hot\"],\n",
    "            dtype=torch.float32,\n",
    "        ).view(-1, 1)\n",
    "\n",
    "        y_i = torch.tensor(\n",
    "            in_sample_transactions.iloc[i][\"choice_one_hot\"], dtype=torch.float32\n",
    "        ).view(-1, 1)\n",
    "\n",
    "        utility_hSi = U[i].view(-1, 1)\n",
    "        exp_utility = torch.exp(utility_hSi)\n",
    "        sum_exp_utility = torch.sum(exp_utility) \n",
    "\n",
    "        for j in range(d):\n",
    "\n",
    "            if hS_i[j] == 1:\n",
    "\n",
    "                p_vec[j] = torch.exp(utility_hSi[j]) / sum_exp_utility\n",
    "            else:\n",
    "\n",
    "                p_vec[j] = 0\n",
    "\n",
    "        loss_value += cross_entropy_loss(p_vec, y_i)\n",
    "    return loss_value / datasize\n",
    "\n",
    "\n",
    "def cross_entropy_loss(p_vec: torch.Tensor, y_vec: torch.Tensor):\n",
    "    for i in range(d):\n",
    "        if y_vec[i] == 1:\n",
    "            return -torch.log(p_vec[i])\n",
    "\n",
    "\n",
    "def squared_loss(p_vec: torch.Tensor, y_vec: torch.Tensor):\n",
    "    return torch.sum((p_vec - y_vec) ** 2)\n",
    "\n",
    "\n",
    "def reg(alphaset: torch.Tensor):\n",
    "\n",
    "    alphaset = alphaset.unsqueeze(2)  # add a dimension \n",
    "\n",
    "    # einsum\n",
    "    result = torch.einsum(\"ikd,ijkl,jle->\", alphaset, K_kernel, alphaset)\n",
    "\n",
    "    return result\n",
    "\n",
    "def compute_gradient():\n",
    "    objective_value = objective(alphaset)\n",
    "    objective_value.backward() \n",
    "    return alphaset.grad\n",
    "\n",
    "optimizer = torch.optim.Adam([alphaset], lr=0.01)\n",
    "for epoch in range(400):\n",
    "    optimizer.zero_grad()  \n",
    "    loss_value = objective(alphaset)\n",
    "\n",
    "    \n",
    "    if loss_value.item() < best_loss:\n",
    "        best_loss = loss_value.item()\n",
    "        epochs_since_improvement = 0  \n",
    "        best_alphaset = alphaset.clone().detach()\n",
    "    else:\n",
    "        epochs_since_improvement += 1\n",
    "        \n",
    "    if epochs_since_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}, Loss: {loss_value.item()}\")\n",
    "        break  \n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Best Loss: {best_loss}\")\n",
    "    \n",
    "    loss_value.backward()  \n",
    "    torch.nn.utils.clip_grad_norm_([alphaset], grad_clip_threshold)\n",
    "    optimizer.step()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9203]), 0.9202792644500732)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = objective(best_alphaset)\n",
    "obj,best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_utility(S:torch.Tensor):\n",
    "    utility_vec = torch.zeros((d,1),dtype=torch.float32)\n",
    "    for i in range(datasize):\n",
    "        S_i = torch.tensor(in_sample_transactions[\"offered_product_one_hot\"][i],dtype=float)\n",
    "        kernel_value = matrix_matern_kernel(S, S_i)\n",
    "        utility_vec += kernel_value @ best_alphaset[i].view(-1,1)\n",
    "    return utility_vec\n",
    "\n",
    "def cal_probability(S:np.ndarray):\n",
    "    utility_vec = cal_utility(S)\n",
    "    sum_exp_utility = torch.sum(torch.exp(utility_vec))\n",
    "    p_vec = torch.zeros(d,dtype=torch.float32)\n",
    "    for i in range(d):\n",
    "        if S[i] == 1:\n",
    "           p_vec[i] = torch.exp(utility_vec[i]) / sum_exp_utility \n",
    "        else:\n",
    "            p_vec[i] = 0\n",
    "            \n",
    "    return p_vec\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "S_test = torch.stack([torch.tensor(sample, dtype=torch.float32) for sample in out_sample_transactions[\"offered_product_one_hot\"]])\n",
    "test_p_vecs = torch.stack([cal_probability(S) for S in S_test])\n",
    "test_choice_vecs = torch.stack([torch.tensor(sample, dtype=torch.float32) for sample in out_sample_transactions[\"choice_one_hot\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1795830837883805, 0.03225008398294449)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse = torch.mean((test_p_vecs- test_choice_vecs) ** 2).item()\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_rmse,test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03160462900996208, 0.17777690797727944)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_train = torch.stack([torch.tensor(sample, dtype=torch.float32) for sample in in_sample_transactions[\"offered_product_one_hot\"]])\n",
    "train_p_vecs = torch.stack([cal_probability(S) for S in S_train])\n",
    "train_choice_vecs = torch.stack([torch.tensor(sample, dtype=torch.float32) for sample in in_sample_transactions[\"choice_one_hot\"]])\n",
    "train_mse = torch.mean((train_p_vecs - train_choice_vecs) ** 2).item()\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_mse, train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "results = [\n",
    "    [float(obj.detach()),test_mse, test_rmse,train_mse,train_rmse] \n",
    "]\n",
    "file_path = f'results/feature_free/hotel_{instance_id}/lambda={lambda_}.csv'\n",
    "file_exists = os.path.exists(file_path)\n",
    "with open(file_path, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    if not file_exists or os.stat(file_path).st_size == 0:\n",
    "        writer.writerow([\"obj\", \"test_mse\", \"test_rmse\", \"train_mse\", \"train_rmse\"])\n",
    "    writer.writerows(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
