{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json \n",
    "import pandas as pd \n",
    "from scipy.special import gamma, kv\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Data, Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_df(json_file_path:str):\n",
    "    with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    in_sample_transactions = data[\"transactions\"][\"in_sample_transactions\"]\n",
    "    out_sample_transactions = data[\"transactions\"][\"out_of_sample_transactions\"]\n",
    "    product_labels = data['product_labels']\n",
    "\n",
    "    in_sample_transactions = pd.DataFrame(in_sample_transactions)\n",
    "    out_sample_transactions = pd.DataFrame(out_sample_transactions)\n",
    "    \n",
    "    # rename 'prodcut' to 'choice' \n",
    "    in_sample_transactions.rename(columns={'product':'choice'}, inplace=True)\n",
    "    out_sample_transactions.rename(columns={'product':'choice'}, inplace=True)\n",
    "    product_labels = pd.DataFrame(\n",
    "        list(product_labels.items()), columns=[\"product_id\", \"product_name\"]\n",
    "    )\n",
    "    return in_sample_transactions, out_sample_transactions,product_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_one_hot(transaction:list,d):\n",
    "    one_hot = np.zeros(d)\n",
    "    for item in transaction:\n",
    "        one_hot[item] = 1\n",
    "    return one_hot\n",
    "\n",
    "def convert_to_one_hot(transactions:pd.DataFrame,d):\n",
    "    transactions[\"offered_product_one_hot\"] = transactions['offered_products'].apply(lambda x : convert_list_to_one_hot(x,d))\n",
    "    transactions['choice_one_hot'] = transactions['choice'].apply(lambda x: convert_list_to_one_hot([x],d))\n",
    "    return transactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offered_products</th>\n",
       "      <th>choice</th>\n",
       "      <th>offered_product_one_hot</th>\n",
       "      <th>choice_one_hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[0, 2, 4, 5]</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[0, 2, 4, 5]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[0, 2, 4, 5]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[0, 2, 4, 5]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[0, 2, 4, 5]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          offered_products  choice              offered_product_one_hot  \\\n",
       "0    [0, 1, 2, 3, 4, 5, 6]       5  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "1    [0, 1, 2, 3, 4, 5, 6]       0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "2    [0, 1, 2, 3, 4, 5, 6]       0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "3    [0, 1, 2, 3, 4, 5, 6]       0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "4    [0, 1, 2, 3, 4, 5, 6]       0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "..                     ...     ...                                  ...   \n",
       "995           [0, 2, 4, 5]       2  [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]   \n",
       "996           [0, 2, 4, 5]       0  [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]   \n",
       "997           [0, 2, 4, 5]       0  [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]   \n",
       "998           [0, 2, 4, 5]       0  [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]   \n",
       "999           [0, 2, 4, 5]       0  [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]   \n",
       "\n",
       "                          choice_one_hot  \n",
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "1    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "..                                   ...  \n",
       "995  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "996  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "997  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "998  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "999  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_id = 5\n",
    "in_sample_transactions, out_sample_transactions ,items= convert_json_to_df(f\"hotel_json/instance_{instance_id}.json\")\n",
    "d = len(items) + 1 # consider the 0 as no-purchase\n",
    "datasize = len(in_sample_transactions)\n",
    "in_sample_transactions = convert_to_one_hot(in_sample_transactions,d)\n",
    "out_sample_transactions = convert_to_one_hot(out_sample_transactions,d)\n",
    "\n",
    "in_sample_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Kernel Implementation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-valued **Matern kernel** $\\tilde{\\boldsymbol{\\mathsf{k}}}$ can be \n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\mathsf{k}}(\\boldsymbol{e}_{S},\\boldsymbol{e}_{S'}) = \\boldsymbol{K} \\otimes \\mathsf{k}_{m}(\\boldsymbol{e}_{S}, \\boldsymbol{e}_{S'})\n",
    "$$\n",
    "where $\\boldsymbol{K}$ is a positive semi-definite matrix. Then \n",
    "\n",
    "$$\n",
    "\\tilde{\\mathsf{k}}^{ij}(\\boldsymbol{e}_{S},\\boldsymbol{e}_{S'}) = K_{ij} \\times\\sigma^{2} \\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\left( \\sqrt{ 2\\nu }  \\frac{\\left\\| \\boldsymbol{e}_{S} - \\boldsymbol{e}_{S'} \\right\\|_{2}  }{\\ell} \\right) K_{\\nu} \\left( \\sqrt{ 2\\nu } \\frac{\\left\\| \\boldsymbol{\\boldsymbol{e}_{S}-\\boldsymbol{e}_{S'}} \\right\\|_{2}  }{\\ell} \\right)\n",
    "$$\n",
    "Add constraint, \n",
    "\n",
    "$$\n",
    "\\mathsf{k}^{ij}(S, S') = \\mathbb{1}(i \\in \\boldsymbol{e}_{S})\\cdot \\mathbb{1}(j \\in \\boldsymbol{e}_{S'}) \\cdot   \\tilde{\\mathsf{k}}^{ij}(\\boldsymbol{e}_{S}, \\boldsymbol{e}_{S'})\n",
    "$$\n",
    "\n",
    "\n",
    "Same with Gaussian kernel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K = np.eye(d) # for simplicity, we assume the kernel matrix is the identity matrix \n",
    "\n",
    "def generate_scalar_matern_kernel(length_scale:float, nu:float, sigma:float):\n",
    "    \"\"\"\n",
    "    Input: kernel parameters and index (i,j)\n",
    "    generate base scalar-valued Matern kernel at (i,j) \n",
    "    return {k_m}_ij\n",
    "    \"\"\"\n",
    "    def kernel(x1:np.ndarray, x2:np.ndarray):\n",
    "\n",
    "        dist = np.linalg.norm(x1 - x2)\n",
    "        \n",
    "        if dist == 0:\n",
    "            return sigma**2\n",
    "\n",
    "        # calculate the factor\n",
    "        factor = (2 ** (1 - nu)) / gamma(nu)\n",
    "        scaled_dist  = np.sqrt(2 * nu) * dist / length_scale\n",
    "        result = sigma**2 * factor * (scaled_dist**nu) * kv(nu, scaled_dist)\n",
    "        return result\n",
    "    return kernel\n",
    "\n",
    "def generate_scalar_gaussian_kernel(length_scale:float, sigma:float):\n",
    "    \"\"\"\n",
    "    Input: kernel parameters and index (i,j)\n",
    "    generate base scalar-valued Gaussian kernel at (i,j)\n",
    "    return {k_g}_ij\n",
    "    \"\"\"\n",
    "    def kernel(x1:np.ndarray, x2:np.ndarray):\n",
    "        \n",
    "        dist = np.linalg.norm(x1 - x2)\n",
    "        return sigma**2 * np.exp(-dist**2 / (2 * length_scale**2))\n",
    "    return kernel\n",
    "\n",
    "def generate_matrix_matern_kernel(length_scale, nu, sigma):\n",
    "    \"\"\"\n",
    "    generate a matrix-valued Matern kernel \n",
    "    \"\"\"\n",
    "    scalar_matern_kernel = generate_scalar_matern_kernel(length_scale, nu, sigma)\n",
    "    def kernel(x1:np.ndarray,x2:np.ndarray):\n",
    "        dim = x1.shape[0]\n",
    "        result = np.zeros((dim,dim))\n",
    "        for i in range(dim):\n",
    "            for j in range(dim):\n",
    "                if x1[i] == 0 or x2[j] == 0:\n",
    "                    result[i,j] = 0\n",
    "                else:\n",
    "                    result[i,j] = scalar_matern_kernel(x1,x2) * K[i,j]\n",
    "        return result\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def generate_matrix_gaussian_kernel(length_scale, sigma):\n",
    "    \"\"\"\n",
    "    generate a matrix-valued Gaussian kernel \n",
    "    \"\"\"\n",
    "    scalar_gaussian_kernel = generate_scalar_gaussian_kernel(length_scale, sigma)\n",
    "    def kernel(x1:np.ndarray,x2:np.ndarray):\n",
    "        dim = x1.shape[0]\n",
    "        result = np.zeros((dim,dim))\n",
    "        for i in range(dim):\n",
    "            for j in range(dim):\n",
    "                if x1[i] == 0 or x2[j] == 0:\n",
    "                    result[i,j] = 0\n",
    "                else:\n",
    "                    result[i,j] = scalar_gaussian_kernel(x1, x2) * K[i,j]\n",
    "        return result\n",
    "    return kernel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_matern_kernel = generate_scalar_matern_kernel(1, 1, 1)\n",
    "scalar_gaussian_kernel = generate_scalar_gaussian_kernel(1, 1)\n",
    "matrix_matern_kernel = generate_matrix_matern_kernel(1, 1, 1)\n",
    "matrix_gaussian_kernel = generate_matrix_gaussian_kernel(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Precalcualte Kernel Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "total_iterations = datasize * datasize\n",
    "with tqdm(total=total_iterations, desc=\"Overall Progress\", unit=\"iteration\") as pbar:\n",
    "    K_kernel = np.zeros((datasize, datasize, d,d))  \n",
    "\n",
    "    for i in range(datasize):\n",
    "        for j in range(datasize):\n",
    "\n",
    "            K_kernel[i, j] = matrix_matern_kernel(\n",
    "                in_sample_transactions[\"offered_product_one_hot\"][i],\n",
    "                in_sample_transactions[\"offered_product_one_hot\"][j],\n",
    "            )\n",
    "\n",
    "            pbar.update(1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 17.133644104003906\n",
      "Epoch 10, Loss: 3.9532620906829834\n",
      "Epoch 20, Loss: 2.744377613067627\n",
      "Epoch 30, Loss: 2.309144973754883\n",
      "Epoch 40, Loss: 1.8242213726043701\n",
      "Epoch 50, Loss: 1.3611044883728027\n",
      "Epoch 60, Loss: 1.1296478509902954\n",
      "Epoch 70, Loss: 0.9803513288497925\n",
      "Epoch 80, Loss: 0.8962939381599426\n",
      "Epoch 90, Loss: 0.8494159579277039\n",
      "Epoch 100, Loss: 0.8338196873664856\n",
      "Epoch 110, Loss: 0.8237236142158508\n",
      "Epoch 120, Loss: 0.8133565783500671\n",
      "Epoch 130, Loss: 0.8054370284080505\n",
      "Epoch 140, Loss: 0.7992307543754578\n",
      "Epoch 150, Loss: 0.7940787076950073\n",
      "Epoch 160, Loss: 0.7897587418556213\n",
      "Epoch 170, Loss: 0.7860875725746155\n",
      "Epoch 180, Loss: 0.7829329371452332\n",
      "Epoch 190, Loss: 0.7802245616912842\n",
      "Epoch 200, Loss: 0.7779388427734375\n",
      "Epoch 210, Loss: 0.776119589805603\n",
      "Epoch 220, Loss: 0.778583288192749\n",
      "Epoch 230, Loss: 0.840743362903595\n",
      "Epoch 240, Loss: 1.2489045858383179\n",
      "Epoch 250, Loss: 1.3080044984817505\n",
      "Epoch 260, Loss: 0.9927216172218323\n",
      "Epoch 270, Loss: 0.8949605822563171\n",
      "Epoch 280, Loss: 0.7915735840797424\n",
      "Epoch 290, Loss: 0.7804070711135864\n",
      "Epoch 300, Loss: 0.7731555104255676\n",
      "Epoch 310, Loss: 0.7696007490158081\n",
      "Epoch 320, Loss: 0.7686141133308411\n",
      "Epoch 330, Loss: 0.7678813934326172\n",
      "Epoch 340, Loss: 0.7673236727714539\n",
      "Epoch 350, Loss: 0.7669744491577148\n",
      "Epoch 360, Loss: 0.7666433453559875\n",
      "Epoch 370, Loss: 0.766343355178833\n",
      "Epoch 380, Loss: 0.7660669088363647\n",
      "Epoch 390, Loss: 0.7657976746559143\n",
      "Epoch 400, Loss: 0.7655428051948547\n",
      "Epoch 410, Loss: 0.7653008103370667\n",
      "Epoch 420, Loss: 0.7650735974311829\n",
      "Epoch 430, Loss: 0.7648507356643677\n",
      "Epoch 440, Loss: 0.7646439075469971\n",
      "Epoch 450, Loss: 0.7644374966621399\n",
      "Epoch 460, Loss: 0.764248788356781\n",
      "Epoch 470, Loss: 0.7640634179115295\n",
      "Epoch 480, Loss: 0.7638833522796631\n",
      "Epoch 490, Loss: 0.7637165188789368\n"
     ]
    }
   ],
   "source": [
    "alphaset = torch.randn((datasize, d), dtype=torch.float32, requires_grad=True)\n",
    "lambda_ = 0.0001\n",
    "\n",
    "def objective(alphaset: torch.Tensor):\n",
    "    U = torch.zeros((datasize, d), dtype=torch.float32)\n",
    "    U = torch.einsum(\"ijab, jb -> ia\", K_kernel, alphaset)\n",
    "\n",
    "    l = loss(U)\n",
    "    r = reg(alphaset)\n",
    "\n",
    "    return l + lambda_ * r\n",
    "\n",
    "\n",
    "\n",
    "def loss(U: torch.Tensor):\n",
    "\n",
    "    loss_value = 0.0\n",
    "    for i in range(datasize):\n",
    "\n",
    "        p_vec = torch.zeros((d, 1), dtype=torch.float32)\n",
    "\n",
    "        hS_i = torch.tensor(\n",
    "            in_sample_transactions.iloc[i][\"offered_product_one_hot\"],\n",
    "            dtype=torch.float32,\n",
    "        ).view(-1, 1)\n",
    "\n",
    "        y_i = torch.tensor(\n",
    "            in_sample_transactions.iloc[i][\"choice_one_hot\"], dtype=torch.float32\n",
    "        ).view(-1, 1)\n",
    "\n",
    "        utility_hSi = U[i].view(-1, 1)\n",
    "        exp_utility = torch.exp(utility_hSi)\n",
    "        sum_exp_utility = torch.sum(exp_utility) \n",
    "\n",
    "        for j in range(d):\n",
    "\n",
    "            if hS_i[j] == 1:\n",
    "\n",
    "                p_vec[j] = torch.exp(utility_hSi[j]) / sum_exp_utility\n",
    "            else:\n",
    "\n",
    "                p_vec[j] = 0\n",
    "\n",
    "        loss_value += cross_entropy_loss(p_vec, y_i)\n",
    "    return loss_value / datasize\n",
    "\n",
    "\n",
    "def cross_entropy_loss(p_vec: torch.Tensor, y_vec: torch.Tensor):\n",
    "    for i in range(d):\n",
    "        if y_vec[i] == 1:\n",
    "            return -torch.log(p_vec[i])\n",
    "\n",
    "\n",
    "def squared_loss(p_vec: torch.Tensor, y_vec: torch.Tensor):\n",
    "    return torch.sum((p_vec - y_vec) ** 2)\n",
    "\n",
    "\n",
    "def reg(alphaset: torch.Tensor):\n",
    "\n",
    "    alphaset = alphaset.unsqueeze(2)  # add a dimension \n",
    "\n",
    "    # einsum\n",
    "    result = torch.einsum(\"ikd,ijkl,jle->\", alphaset, K_kernel, alphaset)\n",
    "\n",
    "    return result\n",
    "\n",
    "def compute_gradient():\n",
    "    objective_value = objective(alphaset)\n",
    "    objective_value.backward() \n",
    "    return alphaset.grad\n",
    "\n",
    "optimizer = torch.optim.Adam([alphaset], lr=0.01)\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()  \n",
    "    loss_value = objective(alphaset)\n",
    "    loss_value.backward()  \n",
    "    optimizer.step()  \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss_value.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7636], grad_fn=<AddBackward0>),\n",
       " tensor(0.0188, grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective(alphaset),reg(alphaset)*lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7954],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0238],\n",
       "        [0.0259],\n",
       "        [0.0835],\n",
       "        [0.0532]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_utility(S:np.ndarray):\n",
    "    utility_vec = torch.zeros((d,1),dtype=torch.float32)\n",
    "    for i in range(datasize):\n",
    "        kernel_value = torch.tensor(matrix_matern_kernel(S, in_sample_transactions[\"offered_product_one_hot\"][i]),dtype=torch.float32)\n",
    "        utility_vec += kernel_value @ alphaset[i].view(-1,1)\n",
    "    return utility_vec\n",
    "\n",
    "def cal_probablity(S:np.ndarray):\n",
    "    utility_vec = cal_utility(S)\n",
    "    sum_exp_utility = torch.sum(torch.exp(utility_vec))\n",
    "    p_vec = torch.zeros((d,1),dtype=torch.float32)\n",
    "    for i in range(d):\n",
    "        if S[i] == 1:\n",
    "           p_vec[i] = torch.exp(utility_vec[i]) / sum_exp_utility \n",
    "        else:\n",
    "            p_vec[i] = 0\n",
    "            \n",
    "    return p_vec\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "S = np.array([1,0,0,1,1,1,1])\n",
    "cal_probablity(S)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
